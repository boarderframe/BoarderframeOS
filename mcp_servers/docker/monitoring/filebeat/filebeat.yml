# Filebeat Configuration for MCP Container Log Collection
# Centralized logging for security analysis and monitoring

filebeat.inputs:
# Docker container logs
- type: docker
  containers.ids: '*'
  processors:
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"
  - decode_json_fields:
      fields: ["message"]
      target: ""
      overwrite_keys: true
  - add_fields:
      target: "mcp"
      fields:
        environment: "${ENVIRONMENT:production}"
        cluster: "mcp-server-manager"

# System logs
- type: log
  enabled: true
  paths:
    - /var/log/syslog
    - /var/log/auth.log
    - /var/log/secure
    - /var/log/messages
  fields:
    log_type: system
    environment: "${ENVIRONMENT:production}"
  fields_under_root: true

# Nginx access logs
- type: log
  enabled: true
  paths:
    - /var/log/nginx/access.log
  json.keys_under_root: true
  json.add_error_key: true
  fields:
    log_type: nginx_access
    service: nginx
  fields_under_root: true
  multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
  multiline.negate: true
  multiline.match: after

# Nginx error logs
- type: log
  enabled: true
  paths:
    - /var/log/nginx/error.log
  fields:
    log_type: nginx_error
    service: nginx
  fields_under_root: true

# Security logs from Falco
- type: log
  enabled: true
  paths:
    - /var/log/falco/*.log
  json.keys_under_root: true
  json.add_error_key: true
  fields:
    log_type: security
    service: falco
  fields_under_root: true

# Suricata logs
- type: log
  enabled: true
  paths:
    - /var/log/suricata/eve.json
  json.keys_under_root: true
  json.add_error_key: true
  fields:
    log_type: ids
    service: suricata
  fields_under_root: true

# Redis logs
- type: log
  enabled: true
  paths:
    - /var/log/redis/*.log
  fields:
    log_type: database
    service: redis
  fields_under_root: true

processors:
# Add hostname
- add_host_metadata:
    when.not.contains.tags: forwarded

# Add container metadata
- add_docker_metadata:
    host: "unix:///var/run/docker.sock"

# Add Kubernetes metadata if available
- add_kubernetes_metadata:
    host: ${NODE_NAME}
    matchers:
    - logs_path:
        logs_path: "/var/log/containers/"

# Enrich with GeoIP data for external IPs
- add_locale:
    format: offset

# Drop empty events
- drop_event:
    when:
      or:
        - equals:
            message: ""
        - is_null:
            message: true

# Extract security events
- script:
    lang: javascript
    source: >
      function process(event) {
        var msg = event.Get("message");
        if (msg && typeof msg === "string") {
          // Mark potential security events
          if (msg.match(/failed|error|attack|intrusion|breach|unauthorized|suspicious/i)) {
            event.Put("security.alert", true);
            event.Put("security.severity", "warning");
          }
          
          // Extract IP addresses
          var ipRegex = /(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})/g;
          var ips = msg.match(ipRegex);
          if (ips) {
            event.Put("security.source_ips", ips);
          }
          
          // Extract user agents
          var uaMatch = msg.match(/"([^"]*user-agent[^"]*)"?/i);
          if (uaMatch) {
            event.Put("http.user_agent", uaMatch[1]);
          }
          
          // Extract HTTP status codes
          var statusMatch = msg.match(/\s(\d{3})\s/);
          if (statusMatch) {
            event.Put("http.response.status_code", parseInt(statusMatch[1]));
            if (parseInt(statusMatch[1]) >= 400) {
              event.Put("security.alert", true);
              event.Put("security.severity", "warning");
            }
          }
        }
      }

# Filter sensitive data
- drop_fields:
    fields: ["host.containerized", "agent.hostname", "ecs.version"]
    ignore_missing: true

output.elasticsearch:
  hosts: ["${ELASTICSEARCH_HOST:elasticsearch:9200}"]
  username: "elastic"
  password: "${ELASTIC_PASSWORD:changeme}"
  
  # Index naming strategy
  indices:
    - index: "mcp-security-%{+yyyy.MM.dd}"
      when.or:
        - equals:
            log_type: "security"
        - equals:
            log_type: "ids"
        - equals:
            security.alert: true
    
    - index: "mcp-access-%{+yyyy.MM.dd}"
      when.equals:
        log_type: "nginx_access"
    
    - index: "mcp-application-%{+yyyy.MM.dd}"
      when.or:
        - contains:
            container.name: "mcp-manager"
        - contains:
            container.name: "mcp-redis"
        - contains:
            container.name: "mcp-ollama"
    
    - index: "mcp-system-%{+yyyy.MM.dd}"
      when.equals:
        log_type: "system"

  # Template settings
  template.enabled: true
  template.pattern: "mcp-*"
  template.settings:
    index:
      number_of_shards: 1
      number_of_replicas: 0
      refresh_interval: 30s
      codec: best_compression
    analysis:
      analyzer:
        mcp_analyzer:
          type: custom
          tokenizer: standard
          filter: ["lowercase", "stop"]

setup.kibana:
  host: "kibana:5601"
  username: "elastic"
  password: "${ELASTIC_PASSWORD:changeme}"

# ILM Policy for log retention
setup.ilm.enabled: true
setup.ilm.rollover_alias: "mcp-logs"
setup.ilm.pattern: "mcp-*"
setup.ilm.policy: "mcp-policy"

# Dashboard and visualization setup
setup.dashboards.enabled: true
setup.dashboards.index: "mcp-*"

# Monitoring
monitoring:
  enabled: true
  elasticsearch:
    hosts: ["${ELASTICSEARCH_HOST:elasticsearch:9200}"]
    username: "elastic"
    password: "${ELASTIC_PASSWORD:changeme}"

# Logging
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

# Performance tuning
queue.mem:
  events: 4096
  flush.min_events: 512
  flush.timeout: 5s

output.elasticsearch.worker: 2
output.elasticsearch.bulk_max_size: 50
output.elasticsearch.flush_bytes: 1024

# HTTP endpoint for monitoring
http:
  enabled: true
  host: "0.0.0.0"
  port: 5066